{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(78263992)\n",
    "\n",
    "# specify device depending on availability of GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wraps a separated dataset to avoid issues while shuffling\n",
    "class WrapperDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "# get the same batch split for inputs and labels\n",
    "def get_batched_x_y(x, y, batch_size, shuffle):\n",
    "    dataset = WrapperDataset(x, y)\n",
    "    batched = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return batched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load(\"X_train.pt\").to_dense()\n",
    "X_val = torch.load(\"X_val.pt\").to_dense()\n",
    "X_test = torch.load(\"X_test.pt\").to_dense()\n",
    "y_train = torch.load(\"y_train.pt\")\n",
    "y_val = torch.load(\"y_val.pt\")\n",
    "y_test = torch.load(\"y_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroPadInput(inputs, amount=50):\n",
    "    # adds zero padding vectors to the end of each sequence\n",
    "    for i in range(len(inputs)):\n",
    "        zero_padding = torch.zeros(inputs[i].shape[0], amount, inputs[i].shape[2])\n",
    "        inputs[i] = torch.cat([inputs[i], zero_padding], dim=1)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = zeroPadInput([X_train, X_val, X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "lstm_layers = 1\n",
    "epochs = 100\n",
    "train_batch_size = 256\n",
    "early_stopping_patience = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[2]\n",
    "sequence_size = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, lstm_layers, pooling):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, lstm_layers, batch_first=True)\n",
    "        self.pool = pooling(sequence_size)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out = self.lstm(x)[0]\n",
    "        pool_out = self.pool(lstm_out.permute(0, 2, 1))\n",
    "        linear_out = self.linear(pool_out.squeeze())\n",
    "        return torch.squeeze(linear_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, model):\n",
    "    myX = x.to(device)\n",
    "    output = model(myX)\n",
    "    return output > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lstm): LSTM(264, 128, batch_first=True)\n",
       "  (pool): MaxPool1d(kernel_size=150, stride=150, padding=0, dilation=1, ceil_mode=False)\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initModel(input_size, hidden_size, lstm_layers, pooling):\n",
    "    model = Net(input_size, hidden_size, lstm_layers, pooling)\n",
    "    model.to(device)\n",
    "    return model\n",
    "model = initModel(input_size, hidden_size, lstm_layers, nn.MaxPool1d)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x, y, model, batch_size, loss_function):\n",
    "    averageLoss = 0.0\n",
    "    averageSensitivity = 0.0\n",
    "    averageSpecificity = 0.0\n",
    "    numBatches = 0\n",
    "    # batch the data set\n",
    "    batched = get_batched_x_y(x, y, batch_size, False)\n",
    "    for xi, yi in batched:\n",
    "        # move data to device\n",
    "        xi = xi.to(device)\n",
    "        yi = yi.to(device)\n",
    "        # forward pass through model\n",
    "        output = model(xi)\n",
    "        # calculate current loss of model\n",
    "        loss = loss_function(output, yi)\n",
    "        # calculate measures\n",
    "        predicted = output > 0\n",
    "        matches = yi == predicted\n",
    "        sensitivity = matches[yi == 1].sum() / (yi == 1).sum()\n",
    "        specificity = matches[yi == 0].sum() / (yi == 0).sum()\n",
    "        # record all values\n",
    "        averageSensitivity += sensitivity.item()\n",
    "        averageSpecificity += specificity.item()\n",
    "        averageLoss += loss.item()\n",
    "        numBatches += 1\n",
    "    averageSensitivity /= numBatches\n",
    "    averageSpecificity /= numBatches\n",
    "    averageLoss /= numBatches\n",
    "    measures = (averageSensitivity, averageSpecificity)\n",
    "    return measures, averageLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordPerformance(measureList, losses, epoch, earlyStop, x, y, x_eval, y_eval, model, loss_function):\n",
    "    # take record of current performance\n",
    "    _, train_loss = test(x, y, model, 1024, loss_function)\n",
    "    measures, val_loss = test(x_eval, y_eval, model, len(y_eval), loss_function)\n",
    "    print(\"Epoch {} Train Loss {:.6f} Val Loss {:.6f} Sensitivity {:.3f} Specificity {:.3f}\"\n",
    "         .format(epoch, train_loss, val_loss, measures[0], measures[1]))\n",
    "    measureList.append(measures)\n",
    "    losses.append((train_loss, val_loss))\n",
    "    earlyStop(val_loss, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchtools import EarlyStopping\n",
    "def train(x, y, x_eval, y_eval, model, epochs, batch_size, loss_function, optimizer):\n",
    "    earlyStop = EarlyStopping(patience=early_stopping_patience, verbose=True)\n",
    "    measureList = []\n",
    "    losses = []\n",
    "    recordPerformance(measureList, losses, \"-\", earlyStop, x, y, x_eval, y_eval, model, loss_function)\n",
    "    for epoch in range(epochs):\n",
    "        # shuffle and batch the data set\n",
    "        batched = get_batched_x_y(x, y, batch_size, True)\n",
    "        for xi, yi in batched:\n",
    "            # move data to device\n",
    "            xi = xi.to(device)\n",
    "            yi = yi.to(device)\n",
    "            # reset previous gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass through model\n",
    "            output = model(xi)\n",
    "            # calculate current loss of model\n",
    "            loss = loss_function(output, yi)\n",
    "            # backprop\n",
    "            loss.backward()\n",
    "            # take optimization step\n",
    "            optimizer.step()\n",
    "        recordPerformance(measureList, losses, epoch, earlyStop, x, y, x_eval, y_eval, model, loss_function)\n",
    "        \n",
    "        if earlyStop.early_stop:\n",
    "            print(\"Early Stop\")\n",
    "            break\n",
    "    # load latest checkpoint\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n",
    "    return measureList, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stupid equally weighted BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - Train Loss 0.712373 Val Loss 0.712352 Sensitivity 0.000 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.712352).  Saving model ...\n",
      "Epoch 0 Train Loss 0.114482 Val Loss 0.114853 Sensitivity 1.000 Specificity 0.000\n",
      "Validation loss decreased (0.712352 --> 0.114853).  Saving model ...\n",
      "Epoch 1 Train Loss 0.112302 Val Loss 0.112781 Sensitivity 1.000 Specificity 0.000\n",
      "Validation loss decreased (0.114853 --> 0.112781).  Saving model ...\n",
      "Epoch 2 Train Loss 0.104136 Val Loss 0.105179 Sensitivity 1.000 Specificity 0.000\n",
      "Validation loss decreased (0.112781 --> 0.105179).  Saving model ...\n",
      "Epoch 3 Train Loss 0.085791 Val Loss 0.089165 Sensitivity 1.000 Specificity 0.000\n",
      "Validation loss decreased (0.105179 --> 0.089165).  Saving model ...\n",
      "Epoch 4 Train Loss 0.079096 Val Loss 0.083260 Sensitivity 0.998 Specificity 0.176\n",
      "Validation loss decreased (0.089165 --> 0.083260).  Saving model ...\n",
      "Epoch 5 Train Loss 0.074630 Val Loss 0.080116 Sensitivity 0.998 Specificity 0.185\n",
      "Validation loss decreased (0.083260 --> 0.080116).  Saving model ...\n",
      "Epoch 6 Train Loss 0.069462 Val Loss 0.075007 Sensitivity 0.998 Specificity 0.194\n",
      "Validation loss decreased (0.080116 --> 0.075007).  Saving model ...\n",
      "Epoch 7 Train Loss 0.063448 Val Loss 0.070577 Sensitivity 0.998 Specificity 0.250\n",
      "Validation loss decreased (0.075007 --> 0.070577).  Saving model ...\n",
      "Epoch 8 Train Loss 0.057313 Val Loss 0.066384 Sensitivity 0.999 Specificity 0.222\n",
      "Validation loss decreased (0.070577 --> 0.066384).  Saving model ...\n",
      "Epoch 9 Train Loss 0.049891 Val Loss 0.059454 Sensitivity 0.999 Specificity 0.528\n",
      "Validation loss decreased (0.066384 --> 0.059454).  Saving model ...\n",
      "Epoch 10 Train Loss 0.043572 Val Loss 0.054500 Sensitivity 0.999 Specificity 0.528\n",
      "Validation loss decreased (0.059454 --> 0.054500).  Saving model ...\n",
      "Epoch 11 Train Loss 0.040782 Val Loss 0.050924 Sensitivity 0.998 Specificity 0.593\n",
      "Validation loss decreased (0.054500 --> 0.050924).  Saving model ...\n",
      "Epoch 12 Train Loss 0.091141 Val Loss 0.100258 Sensitivity 0.984 Specificity 0.694\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 13 Train Loss 0.031277 Val Loss 0.044781 Sensitivity 0.998 Specificity 0.593\n",
      "Validation loss decreased (0.050924 --> 0.044781).  Saving model ...\n",
      "Epoch 14 Train Loss 0.029105 Val Loss 0.043008 Sensitivity 0.999 Specificity 0.583\n",
      "Validation loss decreased (0.044781 --> 0.043008).  Saving model ...\n",
      "Epoch 15 Train Loss 0.030005 Val Loss 0.041282 Sensitivity 0.999 Specificity 0.565\n",
      "Validation loss decreased (0.043008 --> 0.041282).  Saving model ...\n",
      "Epoch 16 Train Loss 0.028110 Val Loss 0.041595 Sensitivity 1.000 Specificity 0.546\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 17 Train Loss 0.025894 Val Loss 0.038951 Sensitivity 0.999 Specificity 0.583\n",
      "Validation loss decreased (0.041282 --> 0.038951).  Saving model ...\n",
      "Epoch 18 Train Loss 0.025502 Val Loss 0.037419 Sensitivity 0.997 Specificity 0.657\n",
      "Validation loss decreased (0.038951 --> 0.037419).  Saving model ...\n",
      "Epoch 19 Train Loss 0.025416 Val Loss 0.039155 Sensitivity 0.999 Specificity 0.602\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 20 Train Loss 0.021706 Val Loss 0.035176 Sensitivity 0.999 Specificity 0.611\n",
      "Validation loss decreased (0.037419 --> 0.035176).  Saving model ...\n",
      "Epoch 21 Train Loss 0.020662 Val Loss 0.036453 Sensitivity 0.999 Specificity 0.630\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 22 Train Loss 0.019523 Val Loss 0.037321 Sensitivity 0.998 Specificity 0.648\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 23 Train Loss 0.021776 Val Loss 0.040556 Sensitivity 0.999 Specificity 0.620\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 24 Train Loss 0.016831 Val Loss 0.036134 Sensitivity 0.996 Specificity 0.685\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 25 Train Loss 0.019048 Val Loss 0.037777 Sensitivity 0.999 Specificity 0.639\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 26 Train Loss 0.016082 Val Loss 0.035772 Sensitivity 0.998 Specificity 0.713\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 27 Train Loss 0.015059 Val Loss 0.036752 Sensitivity 0.997 Specificity 0.685\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n"
     ]
    }
   ],
   "source": [
    "val_measures, losses = train(X_train, y_train, X_val, y_val, model, epochs,\n",
    "                                         train_batch_size, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.032270 Sensitivity 0.999 Specificity 0.676\n"
     ]
    }
   ],
   "source": [
    "test_measures, test_loss = test(X_test, y_test, model, len(y_test), loss_function)\n",
    "print(\"Test Loss {:.6f} Sensitivity {:.3f} Specificity {:.3f}\"\n",
    "         .format(test_loss, test_measures[0], test_measures[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Benign</th>\n",
       "      <th>Predicted Malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Benign</th>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Malicious</th>\n",
       "      <td>6</td>\n",
       "      <td>4274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Benign  Predicted Malicious\n",
       "True Benign                   73                   35\n",
       "True Malicious                 6                 4274"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = predict(X_test, model).cpu()\n",
    "confMatrix = confusion_matrix(y_test.numpy(), y_pred.numpy())\n",
    "pd.DataFrame(confMatrix, index=[\"True Benign\", \"True Malicious\"], columns=[\"Predicted Benign\", \"Predicted Malicious\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeightedBCE():\n",
    "    negative_samples = (y_train == 0).sum()\n",
    "    positive_samples = (y_train == 1).sum()\n",
    "    return nn.BCEWithLogitsLoss(pos_weight=negative_samples/positive_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "Stuff to try:\n",
    "- type of pooling layer (max, avg)\n",
    "- LSTM layers (e.g. 1, 2, 3)\n",
    "- LSTM hidden state size (e.g. 50, 100, 200, 300)\n",
    "- LSTM dropout (e.g. 10%, 20%, 50%)\n",
    "- ?linear layers on top of LSTM (e.g. 1, 2)\n",
    "- ?Adam parameters (learning_rate, decay ...) or other optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPerformances(performances, parameters):\n",
    "    for perf, param in zip(performances, parameters):\n",
    "        print(\"Final {} val loss: {:.6f}\".format(param, perf[1][-1 - early_stopping_patience][1]))\n",
    "        print(\"Final {} val specificity: {:.3f}\".format(param, perf[0][-1 - early_stopping_patience][0]))\n",
    "        print(\"Final {} val sensitivity: {:.3f}\".format(param, perf[0][-1 - early_stopping_patience][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tunePoolingType():\n",
    "    poolingTypes = [nn.MaxPool1d, nn.AvgPool1d]\n",
    "    performances = []\n",
    "    for p in poolingTypes:\n",
    "        torch.manual_seed(78263992)\n",
    "        model = initModel(input_size, 128, 1, p)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        loss_function = getWeightedBCE()\n",
    "        performance = train(X_train, y_train, X_val, y_val, model, epochs, train_batch_size, loss_function, optimizer)\n",
    "        performances.append(performance)\n",
    "    return performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - Train Loss 0.034044 Val Loss 0.034111 Sensitivity 0.000 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.034111).  Saving model ...\n",
      "Epoch 0 Train Loss 0.032975 Val Loss 0.033037 Sensitivity 0.002 Specificity 1.000\n",
      "Validation loss decreased (0.034111 --> 0.033037).  Saving model ...\n",
      "Epoch 1 Train Loss 0.025963 Val Loss 0.026476 Sensitivity 0.902 Specificity 0.704\n",
      "Validation loss decreased (0.033037 --> 0.026476).  Saving model ...\n",
      "Epoch 2 Train Loss 0.016368 Val Loss 0.017926 Sensitivity 0.892 Specificity 0.815\n",
      "Validation loss decreased (0.026476 --> 0.017926).  Saving model ...\n",
      "Epoch 3 Train Loss 0.012494 Val Loss 0.013311 Sensitivity 0.908 Specificity 0.898\n",
      "Validation loss decreased (0.017926 --> 0.013311).  Saving model ...\n",
      "Epoch 4 Train Loss 0.010277 Val Loss 0.011103 Sensitivity 0.921 Specificity 0.926\n",
      "Validation loss decreased (0.013311 --> 0.011103).  Saving model ...\n",
      "Epoch 5 Train Loss 0.008169 Val Loss 0.009580 Sensitivity 0.930 Specificity 0.926\n",
      "Validation loss decreased (0.011103 --> 0.009580).  Saving model ...\n",
      "Epoch 6 Train Loss 0.006316 Val Loss 0.008310 Sensitivity 0.951 Specificity 0.917\n",
      "Validation loss decreased (0.009580 --> 0.008310).  Saving model ...\n",
      "Epoch 7 Train Loss 0.008868 Val Loss 0.012718 Sensitivity 0.981 Specificity 0.796\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 8 Train Loss 0.005865 Val Loss 0.008015 Sensitivity 0.957 Specificity 0.898\n",
      "Validation loss decreased (0.008310 --> 0.008015).  Saving model ...\n",
      "Epoch 9 Train Loss 0.005604 Val Loss 0.008601 Sensitivity 0.972 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 10 Train Loss 0.005516 Val Loss 0.008125 Sensitivity 0.974 Specificity 0.898\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 11 Train Loss 0.004511 Val Loss 0.007154 Sensitivity 0.964 Specificity 0.907\n",
      "Validation loss decreased (0.008015 --> 0.007154).  Saving model ...\n",
      "Epoch 12 Train Loss 0.005081 Val Loss 0.007128 Sensitivity 0.929 Specificity 0.935\n",
      "Validation loss decreased (0.007154 --> 0.007128).  Saving model ...\n",
      "Epoch 13 Train Loss 0.003112 Val Loss 0.006859 Sensitivity 0.974 Specificity 0.926\n",
      "Validation loss decreased (0.007128 --> 0.006859).  Saving model ...\n",
      "Epoch 14 Train Loss 0.003444 Val Loss 0.006972 Sensitivity 0.961 Specificity 0.917\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 15 Train Loss 0.003625 Val Loss 0.008738 Sensitivity 0.985 Specificity 0.870\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 16 Train Loss 0.002976 Val Loss 0.006572 Sensitivity 0.962 Specificity 0.907\n",
      "Validation loss decreased (0.006859 --> 0.006572).  Saving model ...\n",
      "Epoch 17 Train Loss 0.002682 Val Loss 0.005656 Sensitivity 0.974 Specificity 0.917\n",
      "Validation loss decreased (0.006572 --> 0.005656).  Saving model ...\n",
      "Epoch 18 Train Loss 0.002386 Val Loss 0.008095 Sensitivity 0.978 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 19 Train Loss 0.003168 Val Loss 0.006311 Sensitivity 0.957 Specificity 0.944\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 20 Train Loss 0.002125 Val Loss 0.007654 Sensitivity 0.979 Specificity 0.898\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 21 Train Loss 0.002711 Val Loss 0.005997 Sensitivity 0.975 Specificity 0.917\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 22 Train Loss 0.002889 Val Loss 0.008035 Sensitivity 0.982 Specificity 0.880\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 23 Train Loss 0.004925 Val Loss 0.013507 Sensitivity 0.984 Specificity 0.787\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 24 Train Loss 0.002007 Val Loss 0.008823 Sensitivity 0.983 Specificity 0.870\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n",
      "Epoch - Train Loss 0.034041 Val Loss 0.034105 Sensitivity 0.001 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.034105).  Saving model ...\n",
      "Epoch 0 Train Loss 0.027948 Val Loss 0.029440 Sensitivity 0.879 Specificity 0.491\n",
      "Validation loss decreased (0.034105 --> 0.029440).  Saving model ...\n",
      "Epoch 1 Train Loss 0.024415 Val Loss 0.025617 Sensitivity 0.766 Specificity 0.796\n",
      "Validation loss decreased (0.029440 --> 0.025617).  Saving model ...\n",
      "Epoch 2 Train Loss 0.021368 Val Loss 0.023818 Sensitivity 0.871 Specificity 0.722\n",
      "Validation loss decreased (0.025617 --> 0.023818).  Saving model ...\n",
      "Epoch 3 Train Loss 0.019825 Val Loss 0.022097 Sensitivity 0.877 Specificity 0.722\n",
      "Validation loss decreased (0.023818 --> 0.022097).  Saving model ...\n",
      "Epoch 4 Train Loss 0.017941 Val Loss 0.020572 Sensitivity 0.842 Specificity 0.843\n",
      "Validation loss decreased (0.022097 --> 0.020572).  Saving model ...\n",
      "Epoch 5 Train Loss 0.017221 Val Loss 0.020168 Sensitivity 0.839 Specificity 0.815\n",
      "Validation loss decreased (0.020572 --> 0.020168).  Saving model ...\n",
      "Epoch 6 Train Loss 0.015754 Val Loss 0.018557 Sensitivity 0.836 Specificity 0.852\n",
      "Validation loss decreased (0.020168 --> 0.018557).  Saving model ...\n",
      "Epoch 7 Train Loss 0.015516 Val Loss 0.017857 Sensitivity 0.834 Specificity 0.843\n",
      "Validation loss decreased (0.018557 --> 0.017857).  Saving model ...\n",
      "Epoch 8 Train Loss 0.016295 Val Loss 0.022191 Sensitivity 0.892 Specificity 0.796\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 9 Train Loss 0.014111 Val Loss 0.016071 Sensitivity 0.843 Specificity 0.861\n",
      "Validation loss decreased (0.017857 --> 0.016071).  Saving model ...\n",
      "Epoch 10 Train Loss 0.019032 Val Loss 0.023332 Sensitivity 0.880 Specificity 0.722\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 11 Train Loss 0.018629 Val Loss 0.021138 Sensitivity 0.884 Specificity 0.750\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 12 Train Loss 0.017794 Val Loss 0.018912 Sensitivity 0.811 Specificity 0.880\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 13 Train Loss 0.025322 Val Loss 0.027398 Sensitivity 0.613 Specificity 0.852\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 14 Train Loss 0.022891 Val Loss 0.025997 Sensitivity 0.611 Specificity 0.898\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 15 Train Loss 0.027596 Val Loss 0.030118 Sensitivity 0.591 Specificity 0.907\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 16 Train Loss 0.017904 Val Loss 0.020447 Sensitivity 0.803 Specificity 0.889\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n"
     ]
    }
   ],
   "source": [
    "performances = tunePoolingType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max pool val loss: 0.005656\n",
      "Final max pool val specificity: 0.974\n",
      "Final max pool val sensitivity: 0.917\n",
      "Final avg pool val loss: 0.016071\n",
      "Final avg pool val specificity: 0.843\n",
      "Final avg pool val sensitivity: 0.861\n"
     ]
    }
   ],
   "source": [
    "printPerformances(performances, [\"max pool\", \"avg pool\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneLstmLayers():\n",
    "    lstm_layer_list = [1, 2, 3]\n",
    "    performances = []\n",
    "    for l in lstm_layer_list:\n",
    "        torch.manual_seed(78263992)\n",
    "        model = initModel(input_size, 128, l, nn.MaxPool1d)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        loss_function = getWeightedBCE()\n",
    "        performance = train(X_train, y_train, X_val, y_val, model, epochs, train_batch_size, loss_function, optimizer)\n",
    "        performances.append(performance)\n",
    "    return performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - Train Loss 0.034044 Val Loss 0.034111 Sensitivity 0.000 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.034111).  Saving model ...\n",
      "Epoch 0 Train Loss 0.032975 Val Loss 0.033037 Sensitivity 0.002 Specificity 1.000\n",
      "Validation loss decreased (0.034111 --> 0.033037).  Saving model ...\n",
      "Epoch 1 Train Loss 0.025963 Val Loss 0.026476 Sensitivity 0.902 Specificity 0.704\n",
      "Validation loss decreased (0.033037 --> 0.026476).  Saving model ...\n",
      "Epoch 2 Train Loss 0.016368 Val Loss 0.017926 Sensitivity 0.892 Specificity 0.815\n",
      "Validation loss decreased (0.026476 --> 0.017926).  Saving model ...\n",
      "Epoch 3 Train Loss 0.012494 Val Loss 0.013311 Sensitivity 0.908 Specificity 0.898\n",
      "Validation loss decreased (0.017926 --> 0.013311).  Saving model ...\n",
      "Epoch 4 Train Loss 0.010277 Val Loss 0.011103 Sensitivity 0.921 Specificity 0.926\n",
      "Validation loss decreased (0.013311 --> 0.011103).  Saving model ...\n",
      "Epoch 5 Train Loss 0.008169 Val Loss 0.009580 Sensitivity 0.930 Specificity 0.926\n",
      "Validation loss decreased (0.011103 --> 0.009580).  Saving model ...\n",
      "Epoch 6 Train Loss 0.006316 Val Loss 0.008310 Sensitivity 0.951 Specificity 0.917\n",
      "Validation loss decreased (0.009580 --> 0.008310).  Saving model ...\n",
      "Epoch 7 Train Loss 0.008868 Val Loss 0.012718 Sensitivity 0.981 Specificity 0.796\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 8 Train Loss 0.005865 Val Loss 0.008015 Sensitivity 0.957 Specificity 0.898\n",
      "Validation loss decreased (0.008310 --> 0.008015).  Saving model ...\n",
      "Epoch 9 Train Loss 0.005604 Val Loss 0.008601 Sensitivity 0.972 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 10 Train Loss 0.005516 Val Loss 0.008125 Sensitivity 0.974 Specificity 0.898\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 11 Train Loss 0.004511 Val Loss 0.007154 Sensitivity 0.964 Specificity 0.907\n",
      "Validation loss decreased (0.008015 --> 0.007154).  Saving model ...\n",
      "Epoch 12 Train Loss 0.005081 Val Loss 0.007128 Sensitivity 0.929 Specificity 0.935\n",
      "Validation loss decreased (0.007154 --> 0.007128).  Saving model ...\n",
      "Epoch 13 Train Loss 0.003112 Val Loss 0.006859 Sensitivity 0.974 Specificity 0.926\n",
      "Validation loss decreased (0.007128 --> 0.006859).  Saving model ...\n",
      "Epoch 14 Train Loss 0.003444 Val Loss 0.006972 Sensitivity 0.961 Specificity 0.917\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 15 Train Loss 0.003625 Val Loss 0.008738 Sensitivity 0.985 Specificity 0.870\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 16 Train Loss 0.002976 Val Loss 0.006572 Sensitivity 0.962 Specificity 0.907\n",
      "Validation loss decreased (0.006859 --> 0.006572).  Saving model ...\n",
      "Epoch 17 Train Loss 0.002682 Val Loss 0.005656 Sensitivity 0.974 Specificity 0.917\n",
      "Validation loss decreased (0.006572 --> 0.005656).  Saving model ...\n",
      "Epoch 18 Train Loss 0.002386 Val Loss 0.008095 Sensitivity 0.978 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 19 Train Loss 0.003168 Val Loss 0.006311 Sensitivity 0.957 Specificity 0.944\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 20 Train Loss 0.002125 Val Loss 0.007654 Sensitivity 0.979 Specificity 0.898\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 21 Train Loss 0.002711 Val Loss 0.005997 Sensitivity 0.975 Specificity 0.917\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 22 Train Loss 0.002889 Val Loss 0.008035 Sensitivity 0.982 Specificity 0.880\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 23 Train Loss 0.004925 Val Loss 0.013507 Sensitivity 0.984 Specificity 0.787\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 24 Train Loss 0.002007 Val Loss 0.008823 Sensitivity 0.983 Specificity 0.870\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n",
      "Epoch - Train Loss 0.034048 Val Loss 0.034110 Sensitivity 0.000 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.034110).  Saving model ...\n",
      "Epoch 0 Train Loss 0.020183 Val Loss 0.022467 Sensitivity 0.832 Specificity 0.787\n",
      "Validation loss decreased (0.034110 --> 0.022467).  Saving model ...\n",
      "Epoch 1 Train Loss 0.015070 Val Loss 0.019947 Sensitivity 0.896 Specificity 0.713\n",
      "Validation loss decreased (0.022467 --> 0.019947).  Saving model ...\n",
      "Epoch 2 Train Loss 0.012251 Val Loss 0.017123 Sensitivity 0.894 Specificity 0.833\n",
      "Validation loss decreased (0.019947 --> 0.017123).  Saving model ...\n",
      "Epoch 3 Train Loss 0.011020 Val Loss 0.014622 Sensitivity 0.917 Specificity 0.796\n",
      "Validation loss decreased (0.017123 --> 0.014622).  Saving model ...\n",
      "Epoch 4 Train Loss 0.010318 Val Loss 0.016473 Sensitivity 0.928 Specificity 0.796\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 5 Train Loss 0.009066 Val Loss 0.012247 Sensitivity 0.886 Specificity 0.907\n",
      "Validation loss decreased (0.014622 --> 0.012247).  Saving model ...\n",
      "Epoch 6 Train Loss 0.006230 Val Loss 0.011336 Sensitivity 0.949 Specificity 0.889\n",
      "Validation loss decreased (0.012247 --> 0.011336).  Saving model ...\n",
      "Epoch 7 Train Loss 0.005792 Val Loss 0.011200 Sensitivity 0.956 Specificity 0.880\n",
      "Validation loss decreased (0.011336 --> 0.011200).  Saving model ...\n",
      "Epoch 8 Train Loss 0.004400 Val Loss 0.008602 Sensitivity 0.971 Specificity 0.870\n",
      "Validation loss decreased (0.011200 --> 0.008602).  Saving model ...\n",
      "Epoch 9 Train Loss 0.004821 Val Loss 0.008603 Sensitivity 0.967 Specificity 0.889\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 10 Train Loss 0.004494 Val Loss 0.007118 Sensitivity 0.943 Specificity 0.935\n",
      "Validation loss decreased (0.008602 --> 0.007118).  Saving model ...\n",
      "Epoch 11 Train Loss 0.004925 Val Loss 0.006942 Sensitivity 0.933 Specificity 0.954\n",
      "Validation loss decreased (0.007118 --> 0.006942).  Saving model ...\n",
      "Epoch 12 Train Loss 0.003613 Val Loss 0.006756 Sensitivity 0.953 Specificity 0.907\n",
      "Validation loss decreased (0.006942 --> 0.006756).  Saving model ...\n",
      "Epoch 13 Train Loss 0.003424 Val Loss 0.013033 Sensitivity 0.978 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 14 Train Loss 0.002896 Val Loss 0.007891 Sensitivity 0.965 Specificity 0.898\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 15 Train Loss 0.002868 Val Loss 0.009562 Sensitivity 0.975 Specificity 0.889\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 16 Train Loss 0.002775 Val Loss 0.011130 Sensitivity 0.979 Specificity 0.870\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 17 Train Loss 0.003311 Val Loss 0.010645 Sensitivity 0.981 Specificity 0.852\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 18 Train Loss 0.002480 Val Loss 0.009514 Sensitivity 0.971 Specificity 0.907\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 19 Train Loss 0.002278 Val Loss 0.009350 Sensitivity 0.978 Specificity 0.907\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n",
      "Epoch - Train Loss 0.034059 Val Loss 0.034128 Sensitivity 1.000 Specificity 0.000\n",
      "Validation loss decreased (inf --> 0.034128).  Saving model ...\n",
      "Epoch 0 Train Loss 0.034252 Val Loss 0.034279 Sensitivity 0.571 Specificity 0.722\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 1 Train Loss 0.025517 Val Loss 0.026439 Sensitivity 0.809 Specificity 0.704\n",
      "Validation loss decreased (0.034128 --> 0.026439).  Saving model ...\n",
      "Epoch 2 Train Loss 0.023385 Val Loss 0.024142 Sensitivity 0.756 Specificity 0.806\n",
      "Validation loss decreased (0.026439 --> 0.024142).  Saving model ...\n",
      "Epoch 3 Train Loss 0.021199 Val Loss 0.023167 Sensitivity 0.894 Specificity 0.657\n",
      "Validation loss decreased (0.024142 --> 0.023167).  Saving model ...\n",
      "Epoch 4 Train Loss 0.021198 Val Loss 0.022729 Sensitivity 0.789 Specificity 0.787\n",
      "Validation loss decreased (0.023167 --> 0.022729).  Saving model ...\n",
      "Epoch 5 Train Loss 0.021187 Val Loss 0.023075 Sensitivity 0.677 Specificity 0.889\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 6 Train Loss 0.019839 Val Loss 0.022223 Sensitivity 0.895 Specificity 0.667\n",
      "Validation loss decreased (0.022729 --> 0.022223).  Saving model ...\n",
      "Epoch 7 Train Loss 0.020014 Val Loss 0.022471 Sensitivity 0.891 Specificity 0.676\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 8 Train Loss 0.019773 Val Loss 0.022030 Sensitivity 0.812 Specificity 0.806\n",
      "Validation loss decreased (0.022223 --> 0.022030).  Saving model ...\n",
      "Epoch 9 Train Loss 0.019785 Val Loss 0.022322 Sensitivity 0.892 Specificity 0.676\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 10 Train Loss 0.019541 Val Loss 0.022622 Sensitivity 0.896 Specificity 0.667\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 11 Train Loss 0.019385 Val Loss 0.021928 Sensitivity 0.893 Specificity 0.685\n",
      "Validation loss decreased (0.022030 --> 0.021928).  Saving model ...\n",
      "Epoch 12 Train Loss 0.019563 Val Loss 0.022417 Sensitivity 0.869 Specificity 0.685\n",
      "EarlyStopping counter: 1 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train Loss 0.022272 Val Loss 0.024369 Sensitivity 0.714 Specificity 0.880\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 14 Train Loss 0.019317 Val Loss 0.021523 Sensitivity 0.884 Specificity 0.685\n",
      "Validation loss decreased (0.021928 --> 0.021523).  Saving model ...\n",
      "Epoch 15 Train Loss 0.019238 Val Loss 0.021504 Sensitivity 0.884 Specificity 0.685\n",
      "Validation loss decreased (0.021523 --> 0.021504).  Saving model ...\n",
      "Epoch 16 Train Loss 0.020753 Val Loss 0.022400 Sensitivity 0.669 Specificity 0.907\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 17 Train Loss 0.019404 Val Loss 0.021840 Sensitivity 0.851 Specificity 0.694\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 18 Train Loss 0.020276 Val Loss 0.023091 Sensitivity 0.897 Specificity 0.657\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 19 Train Loss 0.018782 Val Loss 0.021491 Sensitivity 0.885 Specificity 0.685\n",
      "Validation loss decreased (0.021504 --> 0.021491).  Saving model ...\n",
      "Epoch 20 Train Loss 0.019058 Val Loss 0.021111 Sensitivity 0.804 Specificity 0.815\n",
      "Validation loss decreased (0.021491 --> 0.021111).  Saving model ...\n",
      "Epoch 21 Train Loss 0.019880 Val Loss 0.021811 Sensitivity 0.725 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 22 Train Loss 0.019209 Val Loss 0.022446 Sensitivity 0.896 Specificity 0.667\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 23 Train Loss 0.018709 Val Loss 0.022068 Sensitivity 0.895 Specificity 0.685\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 24 Train Loss 0.018723 Val Loss 0.021263 Sensitivity 0.886 Specificity 0.676\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 25 Train Loss 0.018690 Val Loss 0.021813 Sensitivity 0.897 Specificity 0.667\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 26 Train Loss 0.018391 Val Loss 0.021417 Sensitivity 0.883 Specificity 0.685\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 27 Train Loss 0.018482 Val Loss 0.021387 Sensitivity 0.817 Specificity 0.796\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n"
     ]
    }
   ],
   "source": [
    "performances = tuneLstmLayers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 1 layer val loss: 0.005656\n",
      "Final 1 layer val specificity: 0.974\n",
      "Final 1 layer val sensitivity: 0.917\n",
      "Final 2 layers val loss: 0.006756\n",
      "Final 2 layers val specificity: 0.953\n",
      "Final 2 layers val sensitivity: 0.907\n",
      "Final 3 layers val loss: 0.021111\n",
      "Final 3 layers val specificity: 0.804\n",
      "Final 3 layers val sensitivity: 0.815\n"
     ]
    }
   ],
   "source": [
    "printPerformances(performances, [\"1 layer\", \"2 layers\", \"3 layers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneLstmStateSize():\n",
    "    lstm_state_sizes = [64, 128, 256, 512]\n",
    "    performances = []\n",
    "    for s in lstm_state_sizes:\n",
    "        torch.manual_seed(78263992)\n",
    "        model = initModel(input_size, s, 1, nn.MaxPool1d)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        loss_function = getWeightedBCE()\n",
    "        performance = train(X_train, y_train, X_val, y_val, model, epochs, train_batch_size, loss_function, optimizer)\n",
    "        performances.append(performance)\n",
    "    return performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - Train Loss 0.034118 Val Loss 0.034178 Sensitivity 0.000 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.034178).  Saving model ...\n",
      "Epoch 0 Train Loss 0.027161 Val Loss 0.028837 Sensitivity 0.827 Specificity 0.602\n",
      "Validation loss decreased (0.034178 --> 0.028837).  Saving model ...\n",
      "Epoch 1 Train Loss 0.024150 Val Loss 0.025929 Sensitivity 0.883 Specificity 0.620\n",
      "Validation loss decreased (0.028837 --> 0.025929).  Saving model ...\n",
      "Epoch 2 Train Loss 0.020685 Val Loss 0.022713 Sensitivity 0.855 Specificity 0.713\n",
      "Validation loss decreased (0.025929 --> 0.022713).  Saving model ...\n",
      "Epoch 3 Train Loss 0.016458 Val Loss 0.018292 Sensitivity 0.848 Specificity 0.796\n",
      "Validation loss decreased (0.022713 --> 0.018292).  Saving model ...\n",
      "Epoch 4 Train Loss 0.014846 Val Loss 0.018622 Sensitivity 0.911 Specificity 0.759\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 5 Train Loss 0.012681 Val Loss 0.014597 Sensitivity 0.924 Specificity 0.824\n",
      "Validation loss decreased (0.018292 --> 0.014597).  Saving model ...\n",
      "Epoch 6 Train Loss 0.010848 Val Loss 0.011709 Sensitivity 0.902 Specificity 0.935\n",
      "Validation loss decreased (0.014597 --> 0.011709).  Saving model ...\n",
      "Epoch 7 Train Loss 0.011286 Val Loss 0.015970 Sensitivity 0.961 Specificity 0.815\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 8 Train Loss 0.008915 Val Loss 0.011006 Sensitivity 0.920 Specificity 0.898\n",
      "Validation loss decreased (0.011709 --> 0.011006).  Saving model ...\n",
      "Epoch 9 Train Loss 0.008807 Val Loss 0.012017 Sensitivity 0.953 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 10 Train Loss 0.007082 Val Loss 0.008182 Sensitivity 0.937 Specificity 0.944\n",
      "Validation loss decreased (0.011006 --> 0.008182).  Saving model ...\n",
      "Epoch 11 Train Loss 0.006712 Val Loss 0.010538 Sensitivity 0.954 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 12 Train Loss 0.007144 Val Loss 0.010022 Sensitivity 0.947 Specificity 0.907\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 13 Train Loss 0.005869 Val Loss 0.008293 Sensitivity 0.968 Specificity 0.935\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 14 Train Loss 0.004807 Val Loss 0.007169 Sensitivity 0.973 Specificity 0.926\n",
      "Validation loss decreased (0.008182 --> 0.007169).  Saving model ...\n",
      "Epoch 15 Train Loss 0.004307 Val Loss 0.006979 Sensitivity 0.973 Specificity 0.935\n",
      "Validation loss decreased (0.007169 --> 0.006979).  Saving model ...\n",
      "Epoch 16 Train Loss 0.004159 Val Loss 0.008807 Sensitivity 0.975 Specificity 0.917\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 17 Train Loss 0.003775 Val Loss 0.007434 Sensitivity 0.971 Specificity 0.935\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 18 Train Loss 0.003349 Val Loss 0.007810 Sensitivity 0.973 Specificity 0.926\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 19 Train Loss 0.003655 Val Loss 0.008382 Sensitivity 0.981 Specificity 0.926\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 20 Train Loss 0.003483 Val Loss 0.008108 Sensitivity 0.963 Specificity 0.944\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 21 Train Loss 0.002843 Val Loss 0.009949 Sensitivity 0.977 Specificity 0.907\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 22 Train Loss 0.003063 Val Loss 0.008492 Sensitivity 0.975 Specificity 0.926\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n",
      "Epoch - Train Loss 0.034044 Val Loss 0.034111 Sensitivity 0.000 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.034111).  Saving model ...\n",
      "Epoch 0 Train Loss 0.032975 Val Loss 0.033037 Sensitivity 0.002 Specificity 1.000\n",
      "Validation loss decreased (0.034111 --> 0.033037).  Saving model ...\n",
      "Epoch 1 Train Loss 0.025963 Val Loss 0.026476 Sensitivity 0.902 Specificity 0.704\n",
      "Validation loss decreased (0.033037 --> 0.026476).  Saving model ...\n",
      "Epoch 2 Train Loss 0.016368 Val Loss 0.017926 Sensitivity 0.892 Specificity 0.815\n",
      "Validation loss decreased (0.026476 --> 0.017926).  Saving model ...\n",
      "Epoch 3 Train Loss 0.012494 Val Loss 0.013311 Sensitivity 0.908 Specificity 0.898\n",
      "Validation loss decreased (0.017926 --> 0.013311).  Saving model ...\n",
      "Epoch 4 Train Loss 0.010277 Val Loss 0.011103 Sensitivity 0.921 Specificity 0.926\n",
      "Validation loss decreased (0.013311 --> 0.011103).  Saving model ...\n",
      "Epoch 5 Train Loss 0.008169 Val Loss 0.009580 Sensitivity 0.930 Specificity 0.926\n",
      "Validation loss decreased (0.011103 --> 0.009580).  Saving model ...\n",
      "Epoch 6 Train Loss 0.006316 Val Loss 0.008310 Sensitivity 0.951 Specificity 0.917\n",
      "Validation loss decreased (0.009580 --> 0.008310).  Saving model ...\n",
      "Epoch 7 Train Loss 0.008868 Val Loss 0.012718 Sensitivity 0.981 Specificity 0.796\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 8 Train Loss 0.005865 Val Loss 0.008015 Sensitivity 0.957 Specificity 0.898\n",
      "Validation loss decreased (0.008310 --> 0.008015).  Saving model ...\n",
      "Epoch 9 Train Loss 0.005604 Val Loss 0.008601 Sensitivity 0.972 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 10 Train Loss 0.005516 Val Loss 0.008125 Sensitivity 0.974 Specificity 0.898\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 11 Train Loss 0.004511 Val Loss 0.007154 Sensitivity 0.964 Specificity 0.907\n",
      "Validation loss decreased (0.008015 --> 0.007154).  Saving model ...\n",
      "Epoch 12 Train Loss 0.005081 Val Loss 0.007128 Sensitivity 0.929 Specificity 0.935\n",
      "Validation loss decreased (0.007154 --> 0.007128).  Saving model ...\n",
      "Epoch 13 Train Loss 0.003112 Val Loss 0.006859 Sensitivity 0.974 Specificity 0.926\n",
      "Validation loss decreased (0.007128 --> 0.006859).  Saving model ...\n",
      "Epoch 14 Train Loss 0.003444 Val Loss 0.006972 Sensitivity 0.961 Specificity 0.917\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 15 Train Loss 0.003625 Val Loss 0.008738 Sensitivity 0.985 Specificity 0.870\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 16 Train Loss 0.002976 Val Loss 0.006572 Sensitivity 0.962 Specificity 0.907\n",
      "Validation loss decreased (0.006859 --> 0.006572).  Saving model ...\n",
      "Epoch 17 Train Loss 0.002682 Val Loss 0.005656 Sensitivity 0.974 Specificity 0.917\n",
      "Validation loss decreased (0.006572 --> 0.005656).  Saving model ...\n",
      "Epoch 18 Train Loss 0.002386 Val Loss 0.008095 Sensitivity 0.978 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 19 Train Loss 0.003168 Val Loss 0.006311 Sensitivity 0.957 Specificity 0.944\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 20 Train Loss 0.002125 Val Loss 0.007654 Sensitivity 0.979 Specificity 0.898\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 21 Train Loss 0.002711 Val Loss 0.005997 Sensitivity 0.975 Specificity 0.917\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 22 Train Loss 0.002889 Val Loss 0.008035 Sensitivity 0.982 Specificity 0.880\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 23 Train Loss 0.004925 Val Loss 0.013507 Sensitivity 0.984 Specificity 0.787\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 24 Train Loss 0.002007 Val Loss 0.008823 Sensitivity 0.983 Specificity 0.870\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n",
      "Epoch - Train Loss 0.034025 Val Loss 0.034089 Sensitivity 0.000 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.034089).  Saving model ...\n",
      "Epoch 0 Train Loss 0.025416 Val Loss 0.026300 Sensitivity 0.825 Specificity 0.759\n",
      "Validation loss decreased (0.034089 --> 0.026300).  Saving model ...\n",
      "Epoch 1 Train Loss 0.015154 Val Loss 0.016545 Sensitivity 0.892 Specificity 0.880\n",
      "Validation loss decreased (0.026300 --> 0.016545).  Saving model ...\n",
      "Epoch 2 Train Loss 0.010610 Val Loss 0.012105 Sensitivity 0.945 Specificity 0.917\n",
      "Validation loss decreased (0.016545 --> 0.012105).  Saving model ...\n",
      "Epoch 3 Train Loss 0.042093 Val Loss 0.044027 Sensitivity 0.975 Specificity 0.472\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 4 Train Loss 0.010413 Val Loss 0.011864 Sensitivity 0.956 Specificity 0.870\n",
      "Validation loss decreased (0.012105 --> 0.011864).  Saving model ...\n",
      "Epoch 5 Train Loss 0.008586 Val Loss 0.010228 Sensitivity 0.908 Specificity 0.944\n",
      "Validation loss decreased (0.011864 --> 0.010228).  Saving model ...\n",
      "Epoch 6 Train Loss 0.006099 Val Loss 0.008085 Sensitivity 0.951 Specificity 0.935\n",
      "Validation loss decreased (0.010228 --> 0.008085).  Saving model ...\n",
      "Epoch 7 Train Loss 0.006165 Val Loss 0.008163 Sensitivity 0.944 Specificity 0.935\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 8 Train Loss 0.005148 Val Loss 0.007235 Sensitivity 0.936 Specificity 0.954\n",
      "Validation loss decreased (0.008085 --> 0.007235).  Saving model ...\n",
      "Epoch 9 Train Loss 0.004755 Val Loss 0.007290 Sensitivity 0.956 Specificity 0.954\n",
      "EarlyStopping counter: 1 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train Loss 0.004124 Val Loss 0.007920 Sensitivity 0.966 Specificity 0.917\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 11 Train Loss 0.004431 Val Loss 0.009577 Sensitivity 0.969 Specificity 0.870\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 12 Train Loss 0.004279 Val Loss 0.008750 Sensitivity 0.973 Specificity 0.898\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 13 Train Loss 0.003136 Val Loss 0.007000 Sensitivity 0.968 Specificity 0.935\n",
      "Validation loss decreased (0.007235 --> 0.007000).  Saving model ...\n",
      "Epoch 14 Train Loss 0.003074 Val Loss 0.007774 Sensitivity 0.963 Specificity 0.935\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 15 Train Loss 0.002677 Val Loss 0.008030 Sensitivity 0.959 Specificity 0.926\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 16 Train Loss 0.003288 Val Loss 0.006653 Sensitivity 0.969 Specificity 0.944\n",
      "Validation loss decreased (0.007000 --> 0.006653).  Saving model ...\n",
      "Epoch 17 Train Loss 0.002584 Val Loss 0.008544 Sensitivity 0.974 Specificity 0.926\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 18 Train Loss 0.002429 Val Loss 0.007754 Sensitivity 0.978 Specificity 0.926\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 19 Train Loss 0.002397 Val Loss 0.007292 Sensitivity 0.966 Specificity 0.935\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 20 Train Loss 0.002158 Val Loss 0.010713 Sensitivity 0.981 Specificity 0.880\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 21 Train Loss 0.002407 Val Loss 0.008041 Sensitivity 0.961 Specificity 0.935\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 22 Train Loss 0.003179 Val Loss 0.010497 Sensitivity 0.982 Specificity 0.889\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 23 Train Loss 0.001708 Val Loss 0.009862 Sensitivity 0.983 Specificity 0.917\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n",
      "Epoch - Train Loss 0.034043 Val Loss 0.034105 Sensitivity 0.000 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.034105).  Saving model ...\n",
      "Epoch 0 Train Loss 0.023259 Val Loss 0.023747 Sensitivity 0.728 Specificity 0.880\n",
      "Validation loss decreased (0.034105 --> 0.023747).  Saving model ...\n",
      "Epoch 1 Train Loss 0.014994 Val Loss 0.016678 Sensitivity 0.886 Specificity 0.796\n",
      "Validation loss decreased (0.023747 --> 0.016678).  Saving model ...\n",
      "Epoch 2 Train Loss 0.012056 Val Loss 0.014480 Sensitivity 0.872 Specificity 0.917\n",
      "Validation loss decreased (0.016678 --> 0.014480).  Saving model ...\n",
      "Epoch 3 Train Loss 0.009417 Val Loss 0.012390 Sensitivity 0.944 Specificity 0.852\n",
      "Validation loss decreased (0.014480 --> 0.012390).  Saving model ...\n",
      "Epoch 4 Train Loss 0.009168 Val Loss 0.010488 Sensitivity 0.888 Specificity 0.954\n",
      "Validation loss decreased (0.012390 --> 0.010488).  Saving model ...\n",
      "Epoch 5 Train Loss 0.007322 Val Loss 0.010075 Sensitivity 0.954 Specificity 0.870\n",
      "Validation loss decreased (0.010488 --> 0.010075).  Saving model ...\n",
      "Epoch 6 Train Loss 0.005241 Val Loss 0.007722 Sensitivity 0.955 Specificity 0.926\n",
      "Validation loss decreased (0.010075 --> 0.007722).  Saving model ...\n",
      "Epoch 7 Train Loss 0.004720 Val Loss 0.007855 Sensitivity 0.955 Specificity 0.907\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 8 Train Loss 0.004840 Val Loss 0.007416 Sensitivity 0.954 Specificity 0.898\n",
      "Validation loss decreased (0.007722 --> 0.007416).  Saving model ...\n",
      "Epoch 9 Train Loss 0.004740 Val Loss 0.007443 Sensitivity 0.953 Specificity 0.926\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 10 Train Loss 0.003754 Val Loss 0.009862 Sensitivity 0.960 Specificity 0.907\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 11 Train Loss 0.003329 Val Loss 0.010592 Sensitivity 0.964 Specificity 0.898\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 12 Train Loss 0.002894 Val Loss 0.010580 Sensitivity 0.970 Specificity 0.917\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 13 Train Loss 0.003230 Val Loss 0.007049 Sensitivity 0.968 Specificity 0.926\n",
      "Validation loss decreased (0.007416 --> 0.007049).  Saving model ...\n",
      "Epoch 14 Train Loss 0.002977 Val Loss 0.008544 Sensitivity 0.969 Specificity 0.917\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 15 Train Loss 0.004007 Val Loss 0.008788 Sensitivity 0.942 Specificity 0.926\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 16 Train Loss 0.002599 Val Loss 0.010025 Sensitivity 0.973 Specificity 0.926\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 17 Train Loss 0.007428 Val Loss 0.009169 Sensitivity 0.969 Specificity 0.898\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 18 Train Loss 0.003398 Val Loss 0.008098 Sensitivity 0.981 Specificity 0.917\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 19 Train Loss 0.002534 Val Loss 0.008227 Sensitivity 0.981 Specificity 0.917\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 20 Train Loss 0.002247 Val Loss 0.007323 Sensitivity 0.977 Specificity 0.926\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n"
     ]
    }
   ],
   "source": [
    "performances = tuneLstmStateSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 64 val loss: 0.006979\n",
      "Final 64 val specificity: 0.973\n",
      "Final 64 val sensitivity: 0.935\n",
      "Final 128 val loss: 0.005656\n",
      "Final 128 val specificity: 0.974\n",
      "Final 128 val sensitivity: 0.917\n",
      "Final 256 val loss: 0.006653\n",
      "Final 256 val specificity: 0.969\n",
      "Final 256 val sensitivity: 0.944\n",
      "Final 512 val loss: 0.007049\n",
      "Final 512 val specificity: 0.968\n",
      "Final 512 val sensitivity: 0.926\n"
     ]
    }
   ],
   "source": [
    "printPerformances(performances, [64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = getWeightedBCE()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - Train Loss 0.034044 Val Loss 0.034111 Sensitivity 0.000 Specificity 1.000\n",
      "Validation loss decreased (inf --> 0.034111).  Saving model ...\n",
      "Epoch 0 Train Loss 0.032975 Val Loss 0.033037 Sensitivity 0.002 Specificity 1.000\n",
      "Validation loss decreased (0.034111 --> 0.033037).  Saving model ...\n",
      "Epoch 1 Train Loss 0.025963 Val Loss 0.026476 Sensitivity 0.902 Specificity 0.704\n",
      "Validation loss decreased (0.033037 --> 0.026476).  Saving model ...\n",
      "Epoch 2 Train Loss 0.016368 Val Loss 0.017926 Sensitivity 0.892 Specificity 0.815\n",
      "Validation loss decreased (0.026476 --> 0.017926).  Saving model ...\n",
      "Epoch 3 Train Loss 0.012494 Val Loss 0.013311 Sensitivity 0.908 Specificity 0.898\n",
      "Validation loss decreased (0.017926 --> 0.013311).  Saving model ...\n",
      "Epoch 4 Train Loss 0.010277 Val Loss 0.011103 Sensitivity 0.921 Specificity 0.926\n",
      "Validation loss decreased (0.013311 --> 0.011103).  Saving model ...\n",
      "Epoch 5 Train Loss 0.008169 Val Loss 0.009580 Sensitivity 0.930 Specificity 0.926\n",
      "Validation loss decreased (0.011103 --> 0.009580).  Saving model ...\n",
      "Epoch 6 Train Loss 0.006316 Val Loss 0.008310 Sensitivity 0.951 Specificity 0.917\n",
      "Validation loss decreased (0.009580 --> 0.008310).  Saving model ...\n",
      "Epoch 7 Train Loss 0.008868 Val Loss 0.012718 Sensitivity 0.981 Specificity 0.796\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 8 Train Loss 0.005865 Val Loss 0.008015 Sensitivity 0.957 Specificity 0.898\n",
      "Validation loss decreased (0.008310 --> 0.008015).  Saving model ...\n",
      "Epoch 9 Train Loss 0.005604 Val Loss 0.008601 Sensitivity 0.972 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 10 Train Loss 0.005516 Val Loss 0.008125 Sensitivity 0.974 Specificity 0.898\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 11 Train Loss 0.004511 Val Loss 0.007154 Sensitivity 0.964 Specificity 0.907\n",
      "Validation loss decreased (0.008015 --> 0.007154).  Saving model ...\n",
      "Epoch 12 Train Loss 0.005081 Val Loss 0.007128 Sensitivity 0.929 Specificity 0.935\n",
      "Validation loss decreased (0.007154 --> 0.007128).  Saving model ...\n",
      "Epoch 13 Train Loss 0.003112 Val Loss 0.006859 Sensitivity 0.974 Specificity 0.926\n",
      "Validation loss decreased (0.007128 --> 0.006859).  Saving model ...\n",
      "Epoch 14 Train Loss 0.003444 Val Loss 0.006972 Sensitivity 0.961 Specificity 0.917\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 15 Train Loss 0.003625 Val Loss 0.008738 Sensitivity 0.985 Specificity 0.870\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 16 Train Loss 0.002976 Val Loss 0.006572 Sensitivity 0.962 Specificity 0.907\n",
      "Validation loss decreased (0.006859 --> 0.006572).  Saving model ...\n",
      "Epoch 17 Train Loss 0.002682 Val Loss 0.005656 Sensitivity 0.974 Specificity 0.917\n",
      "Validation loss decreased (0.006572 --> 0.005656).  Saving model ...\n",
      "Epoch 18 Train Loss 0.002386 Val Loss 0.008095 Sensitivity 0.978 Specificity 0.880\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 19 Train Loss 0.003168 Val Loss 0.006311 Sensitivity 0.957 Specificity 0.944\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 20 Train Loss 0.002125 Val Loss 0.007654 Sensitivity 0.979 Specificity 0.898\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 21 Train Loss 0.002711 Val Loss 0.005997 Sensitivity 0.975 Specificity 0.917\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 22 Train Loss 0.002889 Val Loss 0.008035 Sensitivity 0.982 Specificity 0.880\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 23 Train Loss 0.004925 Val Loss 0.013507 Sensitivity 0.984 Specificity 0.787\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 24 Train Loss 0.002007 Val Loss 0.008823 Sensitivity 0.983 Specificity 0.870\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early Stop\n"
     ]
    }
   ],
   "source": [
    "val_measures, losses = train(X_train, y_train, X_val, y_val, model, epochs,\n",
    "                                         train_batch_size, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.005780 Sensitivity 0.976 Specificity 0.935\n"
     ]
    }
   ],
   "source": [
    "test_measures, test_loss = test(X_test, y_test, model, len(y_test), loss_function)\n",
    "print(\"Test Loss {:.6f} Sensitivity {:.3f} Specificity {:.3f}\"\n",
    "         .format(test_loss, test_measures[0], test_measures[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Benign</th>\n",
       "      <th>Predicted Malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Benign</th>\n",
       "      <td>101</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Malicious</th>\n",
       "      <td>102</td>\n",
       "      <td>4178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Benign  Predicted Malicious\n",
       "True Benign                  101                    7\n",
       "True Malicious               102                 4178"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = predict(X_test, model).cpu()\n",
    "confMatrix = confusion_matrix(y_test.numpy(), y_pred.numpy())\n",
    "pd.DataFrame(confMatrix, index=[\"True Benign\", \"True Malicious\"], columns=[\"Predicted Benign\", \"Predicted Malicious\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
